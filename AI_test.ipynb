{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6wqLQVldkS5",
        "outputId": "200a47a5-fc60-4f35-e3d8-b78809f97705"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # 編碼器\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # 解碼器\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "class EmbeddingDenoiser:\n",
        "    def __init__(self, embedding_model_name=\"all-MiniLM-L6-v2\", load_path=None):\n",
        "        \"\"\"\n",
        "        初始化嵌入向量去噪模型\n",
        "\n",
        "        參數:\n",
        "            embedding_model_name: 要使用的句子嵌入模型名稱\n",
        "            load_path: 若提供，將從此路徑載入預訓練的去噪模型\n",
        "        \"\"\"\n",
        "        # 初始化句子編碼器\n",
        "        self.encoder = SentenceTransformer(embedding_model_name)\n",
        "        self.embedding_dim = self.encoder.get_sentence_embedding_dimension()\n",
        "\n",
        "        # 初始化自動編碼器模型\n",
        "        self.model = Autoencoder(self.embedding_dim)\n",
        "\n",
        "        # 如果提供了模型路徑，則載入模型\n",
        "        if load_path and os.path.exists(load_path):\n",
        "            self.load_model(load_path)\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, texts, noise_level=0.1, epochs=100, batch_size=32, learning_rate=0.001):\n",
        "        \"\"\"\n",
        "        使用文本資料訓練去噪模型\n",
        "\n",
        "        參數:\n",
        "            texts: 文本列表\n",
        "            noise_level: 添加的噪聲水平\n",
        "            epochs: 訓練輪數\n",
        "            batch_size: 批次大小\n",
        "            learning_rate: 學習率\n",
        "        \"\"\"\n",
        "        print(\"生成嵌入向量...\")\n",
        "        # 生成嵌入向量\n",
        "        embeddings = np.array([self.encoder.encode(text) for text in texts])\n",
        "\n",
        "        print(\"添加噪聲...\")\n",
        "        # 添加噪聲\n",
        "        noise = np.random.normal(0, noise_level, size=embeddings.shape)\n",
        "        noisy_embeddings = embeddings + noise\n",
        "\n",
        "        # 轉換為PyTorch張量\n",
        "        clean_tensor = torch.FloatTensor(embeddings).to(self.device)\n",
        "        noisy_tensor = torch.FloatTensor(noisy_embeddings).to(self.device)\n",
        "\n",
        "        # 創建資料載入器\n",
        "        dataset = TensorDataset(noisy_tensor, clean_tensor)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # 定義損失函數和優化器\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "        print(f\"開始訓練，使用設備: {self.device}\")\n",
        "        # 訓練\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for data in dataloader:\n",
        "                noisy_batch, clean_batch = data\n",
        "\n",
        "                # 前向傳播\n",
        "                outputs = self.model(noisy_batch)\n",
        "                loss = criterion(outputs, clean_batch)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # 反向傳播和優化\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            avg_loss = total_loss / len(dataloader)\n",
        "            if (epoch+1) % 10 == 0:\n",
        "                print(f'訓練進度: Epoch [{epoch+1}/{epochs}], 損失: {avg_loss:.6f}')\n",
        "\n",
        "        print(\"訓練完成!\")\n",
        "\n",
        "        # 計算去噪效果\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            denoised = self.model(noisy_tensor)\n",
        "            final_loss = criterion(denoised, clean_tensor).item()\n",
        "\n",
        "        print(f\"最終損失: {final_loss:.6f}\")\n",
        "        return final_loss\n",
        "\n",
        "    def denoise(self, texts=None, embeddings=None, noise_level=0):\n",
        "        \"\"\"\n",
        "        對文本或嵌入向量進行去噪\n",
        "\n",
        "        參數:\n",
        "            texts: 要去噪的文本列表\n",
        "            embeddings: 要去噪的嵌入向量\n",
        "            noise_level: 如果大於0，先添加噪聲再去噪\n",
        "\n",
        "        返回:\n",
        "            去噪後的嵌入向量\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        # 檢查輸入\n",
        "        if texts is None and embeddings is None:\n",
        "            raise ValueError(\"必須提供文本或嵌入向量\")\n",
        "\n",
        "        # 如果提供了文本，先編碼\n",
        "        if embeddings is None:\n",
        "            embeddings = np.array([self.encoder.encode(text) for text in texts])\n",
        "\n",
        "        # 如果需要添加噪聲\n",
        "        if noise_level > 0:\n",
        "            noise = np.random.normal(0, noise_level, size=embeddings.shape)\n",
        "            embeddings = embeddings + noise\n",
        "\n",
        "        # 轉換為PyTorch張量並移到適當的設備\n",
        "        input_tensor = torch.FloatTensor(embeddings).to(self.device)\n",
        "\n",
        "        # 使用模型去噪\n",
        "        with torch.no_grad():\n",
        "            denoised_tensor = self.model(input_tensor)\n",
        "\n",
        "        # 轉換回NumPy數組並返回\n",
        "        return denoised_tensor.cpu().numpy()\n",
        "\n",
        "    def save_model(self, path):\n",
        "        \"\"\"保存模型到指定路徑\"\"\"\n",
        "        model_info = {\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'embedding_dim': self.embedding_dim,\n",
        "        }\n",
        "\n",
        "        # 確保目錄存在\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "\n",
        "        # 保存模型\n",
        "        torch.save(model_info, path)\n",
        "        print(f\"模型已保存到 {path}\")\n",
        "\n",
        "    def load_model(self, path):\n",
        "        \"\"\"從指定路徑載入模型\"\"\"\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"找不到模型文件: {path}\")\n",
        "\n",
        "        # 載入模型\n",
        "        model_info = torch.load(path, map_location=torch.device('cpu'))\n",
        "\n",
        "        # 設置嵌入維度\n",
        "        self.embedding_dim = model_info['embedding_dim']\n",
        "\n",
        "        # 重新初始化模型\n",
        "        self.model = Autoencoder(self.embedding_dim)\n",
        "\n",
        "        # 載入模型權重\n",
        "        self.model.load_state_dict(model_info['model_state_dict'])\n",
        "        print(f\"模型已從 {path} 載入\")\n",
        "\n",
        "\n",
        "# 使用示例\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. 訓練和保存模型\n",
        "    def train_and_save_model():\n",
        "        # 準備訓練數據\n",
        "        training_texts = [\n",
        "            \"Hello, how are you?\",\n",
        "            \"I'm good, thanks for asking!\",\n",
        "            \"What are you up to?\",\n",
        "            \"Just reading a book.\",\n",
        "            \"I love machine learning!\",\n",
        "            \"Neural networks are fascinating.\",\n",
        "            \"Have you tried this new algorithm?\",\n",
        "            \"The weather is nice today.\"\n",
        "        ]\n",
        "\n",
        "        # 初始化模型\n",
        "        denoiser = EmbeddingDenoiser()\n",
        "\n",
        "        # 訓練模型\n",
        "        denoiser.train(training_texts, noise_level=0.1, epochs=100)\n",
        "\n",
        "        # 保存模型\n",
        "        denoiser.save_model(\"models/embedding_denoiser.pt\")\n",
        "\n",
        "    # 2. 載入模型並使用\n",
        "    def load_and_use_model():\n",
        "        # 初始化並載入模型\n",
        "        denoiser = EmbeddingDenoiser(load_path=\"models/embedding_denoiser.pt\")\n",
        "\n",
        "        # 準備測試數據\n",
        "        test_texts = [\n",
        "            \"How's your day going?\",\n",
        "            \"Machine learning is amazing!\"\n",
        "        ]\n",
        "\n",
        "        # 獲取原始嵌入\n",
        "        original_embeddings = np.array([denoiser.encoder.encode(text) for text in test_texts])\n",
        "\n",
        "        # 添加噪聲\n",
        "        noise_level = 0.1\n",
        "        noise = np.random.normal(0, noise_level, size=original_embeddings.shape)\n",
        "        noisy_embeddings = original_embeddings + noise\n",
        "\n",
        "        # 去噪\n",
        "        denoised_embeddings = denoiser.denoise(embeddings=noisy_embeddings)\n",
        "\n",
        "        # 計算MSE\n",
        "        original_vs_noisy_mse = np.mean((original_embeddings - noisy_embeddings) ** 2)\n",
        "        original_vs_denoised_mse = np.mean((original_embeddings - denoised_embeddings) ** 2)\n",
        "\n",
        "        print(f\"測試結果:\")\n",
        "        print(f\"原始 vs 有噪聲 MSE: {original_vs_noisy_mse:.6f}\")\n",
        "        print(f\"原始 vs 去噪後 MSE: {original_vs_denoised_mse:.6f}\")\n",
        "        print(f\"改善幅度: {original_vs_noisy_mse - original_vs_denoised_mse:.6f}\")\n",
        "\n",
        "    # 3. 實際使用案例\n",
        "    def real_world_example():\n",
        "        # 載入模型\n",
        "        denoiser = EmbeddingDenoiser(load_path=\"models/embedding_denoiser.pt\")\n",
        "\n",
        "        # 假設我們有一些來自資料庫或外部API的嵌入向量\n",
        "        # 這些向量可能因為各種原因含有噪聲\n",
        "        texts = [\n",
        "            \"Can you help me with this problem?\",\n",
        "            \"I need assistance with my project.\"\n",
        "        ]\n",
        "\n",
        "        # 編碼並去噪\n",
        "        clean_embeddings = denoiser.denoise(texts=texts)\n",
        "\n",
        "        print(f\"已處理 {len(texts)} 個文本嵌入向量\")\n",
        "        print(f\"去噪後的嵌入向量形狀: {clean_embeddings.shape}\")\n",
        "\n",
        "        # 現在可以使用這些去噪後的向量進行下游任務\n",
        "        # 例如，計算相似度\n",
        "        from sklearn.metrics.pairwise import cosine_similarity\n",
        "        similarity = cosine_similarity([clean_embeddings[0]], [clean_embeddings[1]])[0][0]\n",
        "        print(f\"兩個文本的相似度: {similarity:.4f}\")\n",
        "\n",
        "    # 取消下方註釋來運行不同的範例\n",
        "    # train_and_save_model()\n",
        "    # load_and_use_model()\n",
        "    # real_world_example()\n",
        "\n",
        "    # 或者執行完整流程\n",
        "    print(\"執行完整流程示例\")\n",
        "    train_and_save_model()\n",
        "    load_and_use_model()\n",
        "    real_world_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSU-BHQFLWmK",
        "outputId": "794387db-e1b8-4cbb-8a9f-a6d7aacb55e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "a = int(input())\n",
        "b = a + 1\n",
        "print(b)\n",
        "# 輸出剛剛輸入的數字+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "GDd7AXDygRJh",
        "outputId": "e1455d80-6206-41c6-feb8-58210af61292"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-6-de04fb8c3aaf>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-de04fb8c3aaf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ```python\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "%pip install fastapi\n",
        "%pip install uvicorn\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel, Field\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 匯入之前定義的 Autoencoder 和 EmbeddingDenoiser 類\n",
        "class Autoencoder(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # 編碼器\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        # 解碼器\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(64, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "class EmbeddingDenoiser:\n",
        "    def __init__(self, embedding_model_name=\"all-MiniLM-L6-v2\", load_path=None):\n",
        "        # 初始化句子編碼器\n",
        "        self.encoder = SentenceTransformer(embedding_model_name)\n",
        "        self.embedding_dim = self.encoder.get_sentence_embedding_dimension()\n",
        "\n",
        "        # 初始化自動編碼器模型\n",
        "        self.model = Autoencoder(self.embedding_dim)\n",
        "\n",
        "        # 如果提供了模型路徑，則載入模型\n",
        "        if load_path and os.path.exists(load_path):\n",
        "            self.load_model(load_path)\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def denoise(self, texts=None, embeddings=None, noise_level=0):\n",
        "        self.model.eval()\n",
        "\n",
        "        # 檢查輸入\n",
        "        if texts is None and embeddings is None:\n",
        "            raise ValueError(\"必須提供文本或嵌入向量\")\n",
        "\n",
        "        # 如果提供了文本，先編碼\n",
        "        if embeddings is None:\n",
        "            embeddings = np.array([self.encoder.encode(text) for text in texts])\n",
        "\n",
        "        # 如果需要添加噪聲\n",
        "        if noise_level > 0:\n",
        "            noise = np.random.normal(0, noise_level, size=embeddings.shape)\n",
        "            embeddings = embeddings + noise\n",
        "\n",
        "        # 轉換為PyTorch張量並移到適當的設備\n",
        "        input_tensor = torch.FloatTensor(embeddings).to(self.device)\n",
        "\n",
        "        # 使用模型去噪\n",
        "        with torch.no_grad():\n",
        "            denoised_tensor = self.model(input_tensor)\n",
        "\n",
        "        # 轉換回NumPy數組並返回\n",
        "        return denoised_tensor.cpu().numpy()\n",
        "\n",
        "    def load_model(self, path):\n",
        "        \"\"\"從指定路徑載入模型\"\"\"\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"找不到模型文件: {path}\")\n",
        "\n",
        "        # 載入模型\n",
        "        model_info = torch.load(path, map_location=torch.device('cpu'))\n",
        "\n",
        "        # 設置嵌入維度\n",
        "        self.embedding_dim = model_info['embedding_dim']\n",
        "\n",
        "        # 重新初始化模型\n",
        "        self.model = Autoencoder(self.embedding_dim)\n",
        "\n",
        "        # 載入模型權重\n",
        "        self.model.load_state_dict(model_info['model_state_dict'])\n",
        "        print(f\"模型已從 {path} 載入\")\n",
        "\n",
        "# FastAPI 請求與回應模型\n",
        "class TextDenoiseRequest(BaseModel):\n",
        "    texts: list[str] = Field(..., description=\"要去噪的文本列表\")\n",
        "    noise_level: float = Field(0.0, description=\"可選參數，如果大於0，先添加噪聲再去噪\", ge=0.0)\n",
        "\n",
        "class EmbeddingDenoiseRequest(BaseModel):\n",
        "    embeddings: list[list[float]] = Field(..., description=\"要去噪的嵌入向量列表\")\n",
        "    noise_level: float = Field(0.0, description=\"可選參數，如果大於0，先添加噪聲再去噪\", ge=0.0)\n",
        "\n",
        "class DenoiseResponse(BaseModel):\n",
        "    denoised_embeddings: list[list[float]] = Field(..., description=\"去噪後的嵌入向量\")\n",
        "    shape: list[int] = Field(..., description=\"去噪後嵌入向量的形狀\")\n",
        "    processing_time_ms: float = Field(..., description=\"處理時間（毫秒）\")\n",
        "\n",
        "# 初始化 FastAPI 應用\n",
        "app = FastAPI(\n",
        "    title=\"嵌入向量去噪 API\",\n",
        "    description=\"使用自動編碼器對文本嵌入向量進行去噪\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# 全局變數，存儲模型實例\n",
        "denoiser = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def load_denoiser_model():\n",
        "    \"\"\"在應用啟動時載入模型\"\"\"\n",
        "    global denoiser\n",
        "    model_path = os.getenv(\"MODEL_PATH\", \"models/embedding_denoiser.pt\")\n",
        "\n",
        "    try:\n",
        "        # 初始化去噪器並載入模型\n",
        "        denoiser = EmbeddingDenoiser(load_path=model_path)\n",
        "        print(f\"已載入去噪模型，設備: {denoiser.device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"載入模型失敗: {e}\")\n",
        "        # 如果沒有找到模型，可以選擇訓練一個\n",
        "        if not os.path.exists(model_path):\n",
        "            print(\"模型不存在，正在訓練新模型...\")\n",
        "            # 這裡可以加入簡單的訓練代碼\n",
        "            # 或者只報錯\n",
        "            raise Exception(\"模型不存在，請先訓練模型\")\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    \"\"\"API根路徑，返回簡單的歡迎信息\"\"\"\n",
        "    return {\"message\": \"歡迎使用嵌入向量去噪 API\"}\n",
        "\n",
        "@app.post(\"/denoise/text\", response_model=DenoiseResponse)\n",
        "async def denoise_text(request: TextDenoiseRequest):\n",
        "    \"\"\"\n",
        "    基於文本的去噪API\n",
        "\n",
        "    將文本編碼為嵌入向量，然後進行去噪處理\n",
        "    \"\"\"\n",
        "    global denoiser\n",
        "\n",
        "    if denoiser is None:\n",
        "        raise HTTPException(status_code=503, detail=\"模型尚未載入，請稍後再試\")\n",
        "\n",
        "    try:\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 處理文本\n",
        "        denoised = denoiser.denoise(\n",
        "            texts=request.texts,\n",
        "            noise_level=request.noise_level\n",
        "        )\n",
        "\n",
        "        processing_time = (time.time() - start_time) * 1000  # 轉為毫秒\n",
        "\n",
        "        # 轉換為標準Python類型以進行JSON序列化\n",
        "        denoised_list = denoised.tolist()\n",
        "\n",
        "        return {\n",
        "            \"denoised_embeddings\": denoised_list,\n",
        "            \"shape\": list(denoised.shape),\n",
        "            \"processing_time_ms\": processing_time\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"處理失敗: {str(e)}\")\n",
        "\n",
        "@app.post(\"/denoise/embedding\", response_model=DenoiseResponse)\n",
        "async def denoise_embedding(request: EmbeddingDenoiseRequest):\n",
        "    \"\"\"\n",
        "    基於嵌入向量的去噪API\n",
        "\n",
        "    直接處理提供的嵌入向量，進行去噪處理\n",
        "    \"\"\"\n",
        "    global denoiser\n",
        "\n",
        "    if denoiser is None:\n",
        "        raise HTTPException(status_code=503, detail=\"模型尚未載入，請稍後再試\")\n",
        "\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # 將列表轉換為NumPy數組\n",
        "    embeddings_array = np.array(request.embeddings, dtype=np.float32)\n",
        "\n",
        "    # 處理嵌入向量\n",
        "    denoised = denoiser.denoise(\n",
        "        embeddings=embeddings_array,\n",
        "        noise_level=request.noise_level\n",
        "    )\n",
        "\n",
        "    processing_time = (time.time() - start_time) * 1000  # 轉為毫秒\n",
        "\n",
        "    # 轉換為標準Python類型以進行JSON序列化\n",
        "    denoised_list = denoised.tolist()\n",
        "\n",
        "    return \"denoised_embeddings\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Dict, Any, Union\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import uvicorn\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 匯入之前定義的 Autoencoder 和 EmbeddingDenoiser 類\n",
        "class Autoencoder(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # 編碼器\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        # 解碼器\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(64, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "class EmbeddingDenoiser:\n",
        "    def __init__(self, embedding_model_name=\"all-MiniLM-L6-v2\", load_path=None):\n",
        "        # 初始化句子編碼器\n",
        "        self.encoder = SentenceTransformer(embedding_model_name)\n",
        "        self.embedding_dim = self.encoder.get_sentence_embedding_dimension()\n",
        "\n",
        "        # 初始化自動編碼器模型\n",
        "        self.model = Autoencoder(self.embedding_dim)\n",
        "\n",
        "        # 如果提供了模型路徑，則載入模型\n",
        "        if load_path and os.path.exists(load_path):\n",
        "            self.load_model(load_path)\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def denoise(self, texts=None, embeddings=None, noise_level=0):\n",
        "        self.model.eval()\n",
        "\n",
        "        # 檢查輸入\n",
        "        if texts is None and embeddings is None:\n",
        "            raise ValueError(\"必須提供文本或嵌入向量\")\n",
        "\n",
        "        # 如果提供了文本，先編碼\n",
        "        if embeddings is None:\n",
        "            embeddings = np.array([self.encoder.encode(text) for text in texts])\n",
        "\n",
        "        # 如果需要添加噪聲\n",
        "        if noise_level > 0:\n",
        "            noise = np.random.normal(0, noise_level, size=embeddings.shape)\n",
        "            embeddings = embeddings + noise\n",
        "\n",
        "        # 轉換為PyTorch張量並移到適當的設備\n",
        "        input_tensor = torch.FloatTensor(embeddings).to(self.device)\n",
        "\n",
        "        # 使用模型去噪\n",
        "        with torch.no_grad():\n",
        "            denoised_tensor = self.model(input_tensor)\n",
        "\n",
        "        # 轉換回NumPy數組並返回\n",
        "        return denoised_tensor.cpu().numpy()\n",
        "\n",
        "    def load_model(self, path):\n",
        "        \"\"\"從指定路徑載入模型\"\"\"\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"找不到模型文件: {path}\")\n",
        "\n",
        "        # 載入模型\n",
        "        model_info = torch.load(path, map_location=torch.device('cpu'))\n",
        "\n",
        "        # 設置嵌入維度\n",
        "        self.embedding_dim = model_info['embedding_dim']\n",
        "\n",
        "        # 重新初始化模型\n",
        "        self.model = Autoencoder(self.embedding_dim)\n",
        "\n",
        "        # 載入模型權重\n",
        "        self.model.load_state_dict(model_info['model_state_dict'])\n",
        "        print(f\"模型已從 {path} 載入\")\n",
        "\n",
        "# FastAPI 請求與回應模型\n",
        "class TextDenoiseRequest(BaseModel):\n",
        "    texts: List[str] = Field(..., description=\"要去噪的文本列表\")\n",
        "    noise_level: float = Field(0.0, description=\"可選參數，如果大於0，先添加噪聲再去噪\", ge=0.0)\n",
        "\n",
        "class EmbeddingDenoiseRequest(BaseModel):\n",
        "    embeddings: List[List[float]] = Field(..., description=\"要去噪的嵌入向量列表\")\n",
        "    noise_level: float = Field(0.0, description=\"可選參數，如果大於0，先添加噪聲再去噪\", ge=0.0)\n",
        "\n",
        "class DenoiseResponse(BaseModel):\n",
        "    denoised_embeddings: List[List[float]] = Field(..., description=\"去噪後的嵌入向量\")\n",
        "    shape: List[int] = Field(..., description=\"去噪後嵌入向量的形狀\")\n",
        "    processing_time_ms: float = Field(..., description=\"處理時間（毫秒）\")\n",
        "\n",
        "# 初始化 FastAPI 應用\n",
        "app = FastAPI(\n",
        "    title=\"嵌入向量去噪 API\",\n",
        "    description=\"使用自動編碼器對文本嵌入向量進行去噪\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# 全局變數，存儲模型實例\n",
        "denoiser = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def load_denoiser_model():\n",
        "    \"\"\"在應用啟動時載入模型\"\"\"\n",
        "    global denoiser\n",
        "    model_path = os.getenv(\"MODEL_PATH\", \"models/embedding_denoiser.pt\")\n",
        "\n",
        "    try:\n",
        "        # 初始化去噪器並載入模型\n",
        "        denoiser = EmbeddingDenoiser(load_path=model_path)\n",
        "        print(f\"已載入去噪模型，設備: {denoiser.device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"載入模型失敗: {e}\")\n",
        "        # 如果沒有找到模型，可以選擇訓練一個\n",
        "        if not os.path.exists(model_path):\n",
        "            print(\"模型不存在，正在訓練新模型...\")\n",
        "            # 這裡可以加入簡單的訓練代碼\n",
        "            # 或者只報錯\n",
        "            raise Exception(\"模型不存在，請先訓練模型\")\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    \"\"\"API根路徑，返回簡單的歡迎信息\"\"\"\n",
        "    return {\"message\": \"歡迎使用嵌入向量去噪 API\"}\n",
        "\n",
        "@app.post(\"/denoise/text\", response_model=DenoiseResponse)\n",
        "async def denoise_text(request: TextDenoiseRequest):\n",
        "    \"\"\"\n",
        "    基於文本的去噪API\n",
        "\n",
        "    將文本編碼為嵌入向量，然後進行去噪處理\n",
        "    \"\"\"\n",
        "    global denoiser\n",
        "\n",
        "    if denoiser is None:\n",
        "        raise HTTPException(status_code=503, detail=\"模型尚未載入，請稍後再試\")\n",
        "\n",
        "    try:\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 處理文本\n",
        "        denoised = denoiser.denoise(\n",
        "            texts=request.texts,\n",
        "            noise_level=request.noise_level\n",
        "        )\n",
        "\n",
        "        processing_time = (time.time() - start_time) * 1000  # 轉為毫秒\n",
        "\n",
        "        # 轉換為標準Python類型以進行JSON序列化\n",
        "        denoised_list = denoised.tolist()\n",
        "\n",
        "        return {\n",
        "            \"denoised_embeddings\": denoised_list,\n",
        "            \"shape\": list(denoised.shape),\n",
        "            \"processing_time_ms\": processing_time\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"處理失敗: {str(e)}\")\n",
        "\n",
        "@app.post(\"/denoise/embedding\", response_model=DenoiseResponse)\n",
        "async def denoise_embedding(request: EmbeddingDenoiseRequest):\n",
        "    \"\"\"\n",
        "    基於嵌入向量的去噪API\n",
        "\n",
        "    直接處理提供的嵌入向量，進行去噪處理\n",
        "    \"\"\"\n",
        "    global denoiser\n",
        "\n",
        "    if denoiser is None:\n",
        "        raise HTTPException(status_code=503, detail=\"模型尚未載入，請稍後再試\")\n",
        "\n",
        "    try:\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 將列表轉換為NumPy數組\n",
        "        embeddings_array = np.array(request.embeddings, dtype=np.float32)\n",
        "\n",
        "        # 處理嵌入向量\n",
        "        denoised = denoiser.denoise(\n",
        "            embeddings=embeddings_array,\n",
        "            noise_level=request.noise_level\n",
        "        )\n",
        "\n",
        "        processing_time = (time.time() - start_time) * 1000  # 轉為毫秒\n",
        "\n",
        "        # 轉換為標準Python類型以進行JSON序列化\n",
        "        denoised_list = denoised.tolist()\n",
        "\n",
        "        return {\n",
        "            \"denoised_embeddings\": denoised_list,\n",
        "            \"shape\": list(denoised.shape),\n",
        "            \"processing_time_ms\": processing_time\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"處理失敗: {str(e)}\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"健康檢查端點\"\"\"\n",
        "    global denoiser\n",
        "    return {\n",
        "        \"status\": \"healthy\" if denoiser is not None else \"not_ready\",\n",
        "        \"model_loaded\": denoiser is not None,\n",
        "        \"device\": str(denoiser.device) if denoiser is not None else None\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 設置端口\n",
        "    port = int(os.getenv(\"PORT\", 8000))\n",
        "\n",
        "    # 啟動服務器\n",
        "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=port, reload=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "_FgGBSOTRvtA",
        "outputId": "d1fc7b08-6bef-498c-8835-6a9592c350ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-04-15T02:44:40+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_AUTHTOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n"
          ]
        },
        {
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_AUTHTOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0aff5ae1e6a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# 開 ngrok 隧道\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"FastAPI 公開網址: {public_url}/docs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    429\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_AUTHTOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n."
          ]
        }
      ],
      "source": [
        "%pip install fastapi uvicorn pyngrok nest-asyncio python-multipart\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "import random\n",
        "\n",
        "# 避免 async loop 衝突\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 初始化 FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# 模擬訓練：讀檔後回傳假損失值\n",
        "@app.post(\"/upload/\")\n",
        "async def upload_file(file: UploadFile = File(...)):\n",
        "    content = await file.read()\n",
        "    text = content.decode(\"utf-8\")\n",
        "\n",
        "    # 模擬訓練邏輯\n",
        "    fake_loss = round(random.uniform(0.01, 1.0), 4)\n",
        "    file_len = len(text.split())\n",
        "\n",
        "    return {\n",
        "        \"filename\": file.filename,\n",
        "        \"word_count\": file_len,\n",
        "        \"loss\": fake_loss\n",
        "    }\n",
        "\n",
        "# 設定 ngrok authtoken\n",
        "# 將 \"YOUR_AUTHTOKEN\" 替換成你自己的 authtoken\n",
        "ngrok.set_auth_token(\"YOUR_AUTHTOKEN\")\n",
        "\n",
        "# 開 ngrok 隧道\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"FastAPI 公開網址: {public_url}/docs\")\n",
        "\n",
        "# 啟動 server（背景）\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
